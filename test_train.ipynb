{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49018b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from model import JetTransformer\n",
    "from helpers_train import *\n",
    "import matplotlib.pyplot as plt\n",
    "import ipykernel\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79945ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added start token!\n",
      "Added stop token!\n",
      "Max bins without padding: Num_bins: [42, 32, 32]\n",
      "---> Number of different pt, eta, phi without padding: Total_voc_bin: [44, 34, 34]\n",
      "Bins reserved for PAD: [43, 33, 33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args used for training: {'data_path': 'processed_data/TTBar_5000_train.h5', 'num_const': 20, 'add_start': True, 'add_stop': True, 'num_epochs': 20, 'lr': 0.001, 'hidden_dim': 256, 'num_layers': 8, 'num_heads': 4, 'dropout': 0.1, 'n_pt': 40, 'n_eta': 30, 'n_phi': 30, 'causal_mask': True, 'output_path': 'output/', 'name': 'debug', 'contin': False, 'batch_size': 20, 'n_jets': 100, 'n_jets_val': 60}\n",
      "Added start token!\n",
      "Added stop token!\n",
      "Max bins without padding: Num_bins: [42, 32, 32]\n",
      "---> Number of different pt, eta, phi without padding: Total_voc_bin: [44, 34, 34]\n",
      "Bins reserved for PAD: [43, 33, 33]\n"
     ]
    }
   ],
   "source": [
    "testModel = JetTransformer()\n",
    "\n",
    "testModel = load_model_checkpoint(\"output/checkpoints/TTBar_600000_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef38195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset: test | n_jets = None | processed_data/TTBar_5000_test.h5\n",
      "Added start token. New bins are now: [41, 31, 31]\n",
      "Added stop token. New bins are now: [42, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "testSet = DataLoader(\n",
    "    JetDataSet(\"processed_data/TTBar_5000_test.h5\", \"test\"),\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d721d310",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'model' has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m probabilities = np.array([])\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m testSet:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     logits = \u001b[43mtestModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m(x)\n\u001b[32m      6\u001b[39m     probs = testModel.probability(logits, x, logarithmic= \u001b[38;5;28;01mTrue\u001b[39;00m, topk = \u001b[32m5000\u001b[39m)\n\u001b[32m      8\u001b[39m     probabilities = np.append(probabilities, probs.detach().numpy())\n",
      "\u001b[31mAttributeError\u001b[39m: module 'model' has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "probabilities = np.array([])\n",
    "\n",
    "for x in testSet:\n",
    "    \n",
    "    logits = testModel.forward(x)\n",
    "    probs = testModel.probability(logits, x, logarithmic= True, topk = 5000)\n",
    "\n",
    "    probabilities = np.append(probabilities, probs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccdb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4), dpi = 150)\n",
    "\n",
    "ax.hist(\n",
    "    probabilities,\n",
    "    bins=100,                 # adjust for smoothness\n",
    "    density=True,            # normalization\n",
    "    histtype=\"step\",\n",
    "    linewidth=1.0,\n",
    "    color=\"black\",\n",
    "    label=\"Top\"\n",
    ")\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"$\\log(p)$\")\n",
    "ax.set_ylabel(\"Normalized distribution\")\n",
    "ax.set_title(\"Top\")\n",
    "\n",
    "# ticks and frame styling\n",
    "#ax.tick_params(axis=\"both\", which=\"major\", labelsize=14, width=1.8, length=7)\n",
    "#for spine in ax.spines.values():\n",
    "#    spine.set_linewidth(1.8)\n",
    "\n",
    "# legend in upper-left with box\n",
    "ax.legend(\n",
    "    #loc=\"upper left\",\n",
    "    frameon=True,\n",
    "    framealpha=1.0,\n",
    "    #fontsize=18,\n",
    "    borderpad=0.8,\n",
    "    handlelength=2.5\n",
    ")\n",
    "\n",
    "# optional: match x-range style from example\n",
    "#ax.set_xlim(probabilities.min(), 0)\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hep_foundation_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
